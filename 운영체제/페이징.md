# 배경
- - -

실행 중인 코드는 반드시 물리 메모리에 있어야 한다는 전제 조건은 타당해 보이지만, 프로그램의 최대 크기를 물리 메모리의 크기로 제한하기 때문에
환영할 요구 조건은 아니다. 실제 프로그램을 확인해보면 많은 경우에 프로그램 전체가 메모리에 늘 올라와 있어야 하는게 아닌걸 발견할 수 있다.

프로그램을 일부분만 메모리에 올려놓고 실행할 수 있다면, 많은 이점이 있다.

1. 프로그램이 물리 메모리 크기에 의해 더 이상 제약받지 않고, 개발자는 매우 큰 공간을 가정하고 프로그램을 제작할 수 있다.
2. 각 프로그램이 더 작은 메모리를 차지하여 더 많은 프로그램을 동시에 수행할 수 있다. 응답 시간은 늘어나지 않지만, CPU 이용률 및 처리율이 높아진다.
3. 프로그램을 메모리에 올리고 Swap 하는데 필요한 I/O 횟수가 줄어들어 프로그램이 보다 빨리 실행된다.

# 가상 메모리
- - -

**가상 메모리는** 실제의 물리 메모리 개념과 논리 메모리 개념을 분리한 것이다. 이로써, 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 제공한다.

가상 주소 공간은 그 프로세스가 메모리에 저장되는 논리적인 모습을 말하며, 보통 연속적인 공간을 차지한다.
* 물리 메모리는 페이지 프레임 단위로 구성되어 있어, 물리 메모리에서도 연속적으로 존재하지 않을 수 있다.

# 요구 페이징
- - -

실행 프로그램을 SSD, HDD에서 메모리로 적재하는 걸 생각해보다. 먼저, 프로그램 실행 시작 시 프로그램 전부를 물리 메모리에 적재하는 것이다.
그런데 초기에는 프로그램 전체가 메모리에 다 있을 필요가 없을 수 있다. 그러나 불필요한 프로그램의 적제도 하게 될 수 있다. 

또 다른 방법으로는 필요한 페이지만 적제하는 것이다. **요구 페이징**이라고 하며 일반적으로 사용된다.
프로그램 실행 중 필요할 때만 페이지가 적재되며, 접근하지 않은 메모리는 물리 메모리로 적재되지 않는다. 

## 개념
기본 개념은 필요할 때만 페이지를 메모리에 적재 하는 것이다. 결과적으로 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고 일부는 저장장치에 있다.

이 둘을 구별하기 위해 유효, 무효 flag bit를 하나 설정하여, 유효로 설정되어 있으면 페이지가 메모리에 있고, 무효라면 페이지가 메모리에 없다는 뜻이다.
무효로 된 메모리에 접근하기전 까지는 아무런 일도 발생하지 않지만, 무효로 된 메모리에 접근하면 **페이지 폴트 트랩**이 발생한다.
페이징 알고리즘이 운영체제에게 트랩을 걸고 -> 페이지 폴트를 처리하게 된다.

1. 프로세스에 대한 내부 테이블을 검사해서 메모리 참조가 유효, 무효인지 확인한다.
2. 만약 무효한 페이지에 대한 참조하면 프로세스는 중단된다.
3. 빈 공간 -> 가용 프레임을 찾고, 보조저장장치에서 가용한 프레임으로 읽도록 요청한다.
4. 읽고나면 이제 페이지 테이블을 갱신하고(유효로) 트랩으로 중단되었던 프로세스를 다시 수행한다.
5. 이제 다시 수행하게 되면 메모리가 있던 것 처럼 접근한다.

극단적으로는 메모리에 페이지가 하나도 없는 상황에서 실행할 수 있다.
처음에 실행할 때마다 메모리 폴트가 발생하지만, 전부 적재된 이후에는 더 이상 폴트가 나지 않는다.
이것이 순수 요구 페이징이라는 방법이다.

### 성능

요구 페이징은 컴퓨터 시스템 성능에 큰 영향을 줄 수 있다.

과정을 나열해보자

1. 운영체제에 트랩을 요청한다
2. 레지스터들과 프로세스 상태 저장
3. 인터럽트 원인이 페이지 폴트임을 찾는다.
4. 페이지 참조가 유효한지 보고, 보조 저장장치 페이지 위치를 알아낸다.
5. 가용 프레임에게 읽기 요청한다.
6. 기다리는 동안 CPU는 다른 일을 한다.
7. 저장장치가 인터럽트를 건다
8. PCB Switch가 발생하고, 페이지 테이블에 메모리 변화를 기록한다.
9. CPU 코어가 자기 차례로 오기까지 다시 기다린다.
10. 다시 실행한다.

그렇기 때문에 컴퓨터 역량에 따라 페이지를 잘 조절해야 한다.


# 페이지 교체
- - -

빈 페이지가 없다면, 현재 사용하지 않는 프레임을 찾아 그것을 비워버리고, 그 프레임의 내용을 스왑 공간에 쓰게 된다.

## 페이지 교체 알고리즘
- - -
1. FIFO: 가장 간단한 페이지 교체 알고리즘은 FIFO 알고리즘이다. 메모리에 올라온지 가장 오래된 페이지를 내쫒는다.
페이지가 올라온 시간을 페이지마다 기록하거나, 올라온 순서로 큐를 만들어가지고 있어도 된다.

하지만 FIFO에서 발생하는 문제가 있는데, Belady의 모순이라는 현상이다. 그러니까 프로세스에 프레임은 더 줬는데 페이지 폴트가 
더 증가하는 현상이다. FIFO는 프로세스 상관없이 프로세스 페이지가 서로 겹쳐져서 있는 경우 폴트가 많이 발생한다.

2. LRU: 페이지가 사용될 시간을 이용해 가장 오랜 기간 동안 사용되지 않은 페이지를 교체하는 계념이다.
LRU 알고리즘은 페이지마다 마지막 사용시간을 유지한다. 페이지 교체시에 LRU는 가장 오랫동안 사용되지 않은 페이지를 선택한다.
좋은 알고리즘으로 인정받고 있으나, 문제는 어떻게 이 알고리즘을 구현하느냐 하는 것이다.
LRU 알고리즘은 하드웨어의 지원이 필요하며, 두가지의 구현 방법이 가능하다.

계수기: 가장 간단한 방법으로 각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리적인 시계나 계수기를 추가한다.
메모리가 접근될 때마다 시간은 증가하고 페이지에 대한 참조가 일어날 때마다 페이지 사용 시간 필드에 시간 내용이 복사된다.
이렇게 각 페이지의 마지막 시간 내용을 유지할 수 있다. 
이 기법에서는 LRU 대상 페이지를 찾기 위해 탐색이 필요하고, 시간값 관리와 함께, 시간 값의 overflow도 고려해야한다.

스택: 페이지 교체 번호의 스택을 유지하는 것이다. 페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되어 스택 꼭대기에 놓이게 된다.
이런 방식으로 스택 꼭대기는 항상 가장 최근에 사용되고, 밑바닥은 가장 오래 안쓴 페이지이다. 이를 구현하기 위해 더블 링크 리스트로 구현하며
페이지를 탐색하지 않아도 된다.

3. LRU 근사: 참조 비트 형태로 대체할 수 있으며, 모든 참조 비트는 운영체제에 의해 0으로 채워진다. 프로세스가 실행되며 참조되는 페이지 비트는
하드웨어가 1로 세팅한다. 그리고 주기적으로 다시 0으로 바꿔, 페이지에 대한 LRU 근사로 유지한다.

